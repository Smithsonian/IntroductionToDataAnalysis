---
title: "Introduction to Data Analysis in R"
author: "Smithsonian's National Zoo & Conservation Biology Institute"
date: '`r format(Sys.time(), "%d %B %Y")`'
output:
  html_document:
    toc: true
    toc_depth: 4
    toc_float: 
      collapsed: true
      smooth_scroll: true
    number_sections: false
pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction to Data Analysis

Now that you've learned the basics of R programming, we'll take things a step further and start working on your skills related to data analysis.  You will likely be unfamiliar with some of the operations you need to execute in this exercise. Part of the goal with this exercise, however, is for you to become more familiar with the *help* commands in R and with the internet solutions that exist.  Our ultimate goal is to make you aware of the tools that are available so that you can become an effective problem solver, working independently on data analyses.

# Running Code in a Script

So far, we've run code in the Console.  This is fine for quick queries. For anything to be shareable, reproducible, and to reduce our own efforts in the long-term, we should run code via a script.  An R script is a just a simple text file.  R-Studio uses the script by copying R commands from text in the file and pastes them into the Console as if you were manually entering the commands yourself.  This greatly enhances our ability to build off what we have created in the past, learn from previous experience, and quickly re-run analyses when new data are received.  To create an R script:

1. From the "file" mean, select "New File"
2. Click "R Script from the list of options

R-Studio will open your R script automatically after creating it.  Notice that the scripting window appears above the Console in what's known as the **Source** pane.

3. Save the R script in your working directly in the `Scripts` folder.  Name this file `IntroDataAnalysis.R`. 

![Figure 1: Create a script for running analyses](Fig1.png)
<br>
At the top of your script, provide brief information that describes the content of your script.  The content is up to you, but should briefly identify who created the file, when the file was created, and what the script does.  This will help when you return to the file at a later date or if you decide to share the file with a colleague in the future.  Remember that anything after the `#` symbol is a comment.  Use this symbol to make your code more readable, similar to below.  

```{r, eval=F}
# ******************************************************************
# ******************************************************************

# Project: Introduction to Data Analysis in R
# Description: A script which details some basic commands on how to manipulate data
# Author: <Your Name>
# Date Initialized: <dd month yyyy>

# ******************************************************************
# ******************************************************************
```

## Running an R Script

Running code via an R script is different than running code in the Console.  To interpret and run the code you've written, R needs you to send the code from the script to the Console.  Some common ways to run your code include:

1. Highlight the line of code you want to run and use the shortcut `Ctrl` + `Enter` (Windows) or `command` + `return` (Mac).  
2. Highlight your code a physically click the `Run` button in the top right of the Source pane with your mouse.

## Clearing your Workspace

You'll find that your Environment (Workspace) in the upper right panel will quickly become full with user-defined objects.  It's generally good practice to work with a clean Workspace when starting a session.  I generally start all my scripts with the following command to make sure you are starting fresh, something we will do to help develop good programming practices and reduce clutter.

```{r, eval=F}
# Clean your workspace/remove all objects
rm(list=ls())

# You can also remove a specific dataset using the following command
#rm(dataset)
```

# Data Table Manipulation with `Dplyr`

The most basic R skill is to query and manipulate data tables. As a beginner programmer, it is imperative to familiarize yourself with how to manipulate data.  Reinforcing these skills is like expanding your vocabulary in the new language that you are learning and is a great way to improve your R proficiency. If you wish to become really good at R, but don't know where to start, start with data table manipulation! 

<div style="float:right">
<img width="150" height="150" src="dplyr.jpg">
</div>

The base R functions that come with the default R installation have the capacity for almost all the table manipulation needs (e.g., `split(), subset(), apply(), sapply(), lapply(), tapply(), aggregate()`). However, sometimes their syntax are less user-friendly and intuitive than some of the special packages built for table manipulation purposes. So, here we are introducing a few of the most useful table manipulation functions within `dplyr` package. 

Note that you will have to use `install.packages()` and `library()` function to download and activate the `dplyr` before using it. You only need to install the package once on your computer.  You will need, however, to 'activate' the package any time you want to use the functions that exist within the package. 

```{r, eval = T, message = F, warning = F}
#install.packages("dplyr")
library(dplyr)
```

## Reading/Importing Data

R has multiple functions for reading in table data.  Here we'll use the base function `read.csv()` to import a table named `panda_data.csv` that is located in your `Data` folder. Text files (`.txt`) can be imported using the function `read.delim()`.  See the help files for each function and search Google for information on other functions to read other data types.

View the first few rows of the data table using the function `head()` or click on the dataframe in the Environment/History panel.

```{r, eval = T, echo = T, warning=F, message=F}
# Read dataset
panda_data <- read.csv(file="Data/panda_data.csv")

# Look at the data
head(panda_data)
```

**Questions**: 

1. Can you change the number of rows that are displayed with the `head()` function?  
2. How would you print the first 3 rows?
3. How would you print rows 4 thru 6? 
4. What are the dimensions of the dataframe?  How many rows and columns are there?
5. Can you guess how you might look at the last few rows of the dataframe?

```{r, eval = F, echo = F, warning=F, message=F}
# Print the first 3 rows
head(panda_data, n = 3)

# Print rows 4 thru 6
panda_data[4:6,]

# Dataframe dimensions
dim(panda_data)
nrow(panda_data)
ncol(panda_data)

# Print the tail
tail(panda_data)
```

## Selecting Columns 

The function `select()` is a powerful tool for selecting columns of interest.  You must specify the dataset you want to query and then also provide an expression for selecting columns of interest (`select(.data, expression)`).  A few examples are provided below 

```{r, warning = F, message = F}
# select column called panda_name
select(panda_data, panda_name) 

# select all columns in the data except panda_name
select(panda_data, -panda_name)

# select a range of columns, from age to sex
select(panda_data, age:sex)
```

Various selection helpers also exist, including:

* `starts_with`: Expression select multiple columns that start with the same text.   
* `ends_with()`: Expression to select columns that end with the same text.  
* `contains()`: Expression to select columns that contain the same text.  
* `matches()`: Expression to select columns that match a regular expression.  
* `one_of()`: Expression to select columns that are from a group of names. 

```{r, warning = F, message = F}
# select all columns that start with "genetic" in their column names
select(panda_data, starts_with("genetic")) 
```

**Questions**: 

1. Select all the columns that contain "value" in the column name.
2. Select or exclude two columns: `panda_name` and `age`.  

```{r, warning = F, message = F, eval = F, echo = F}
# Select all the columns that contain "value" in the column name.
select(panda_data, contains("value")) 

# Select or exclude two columns: `panda_name` and `age`. 
select(panda_data, c(panda_name, age)) 
select(panda_data, !c(panda_name, age))
```

## Filtering Data

`Filter()` is similar to `select()`, except that you are selecting specific rows that satisfy a specific requirement based on the column value.

![Artwork by [Allison Horst](https://allisonhorst.com/allison-horst)](dplyr_filter.png)

<br>
Words here

```{r}
filter(panda_data, age %in% c(4,5))
filter (panda_data, age>5) # select rows that have age>5
filter(panda_data, age>5 | weight_kg>100) # select rows that have age>5 OR weight_kg >100 
filter (panda_data, age>5 & base =="CD") # select rows that have age>5 AND base column has CD has entry
filter(panda_data, age %in% c(4, 6)) # select rows that have age included a user defined list
```

**Questions**:

1: Select rows with `NA` in the genetic_value2 column.   
2: Select rows whose panda_name column are `bao_bao` or `bei_bei`.

```{r, warning = F, message = F, eval = F, echo = F}
# Select rows with `NA` in the genetic_value2 column. 
filter(panda_data, is.na(genetic_value2)) 

# Select rows whose panda_name column are `bao_bao` or `bei_bei`
filter(panda_data, panda_name == 'bao_bao' | panda_name == 'bei_bei') 
```

##  pipe operator `%>%`   
This operator allows you to pipe the output from one function to the input of the next function. Instead of nesting functions (reading from the inside to the outside), the idea of of piping is to read the functions from left to right. It can also help you avoid creating and saving a lot of intermediate variables that you dont need to keep

```{r}
pipe_result<- panda_data %>%
  select(panda_name, sex) %>%
  head()
pipe_result
```
> Question: Try to use pipe operator to 1. select all columns contain "genetic" in their names, 2. select the rows with genetic_value1  >80 AND genetic_value2 <90

### `arrange()` 
Arrange or re-order rows based on their value, the rows are arranged by default in ascending order  
```{r}
order_data1<- panda_data %>% 
	arrange(ID) 
order_data1

order_data2<- panda_data %>% 
	select(starts_with("genetic")) %>%
	arrange(genetic_value1, genetic_value2) %>%
	head
order_data2
# Now we learn pipe operator, can you understand what order_data1 and order_data2 are producing? 
```
> Question: Can you arrange the table first by age and then by panda weight in decending order?

###  `mutate()`   
Create new column(s) and define their values
```{r}
new_col<- panda_data %>%
	mutate(new_col = genetic_value1 - genetic_value2)  # before = is the name of the new column we are producing, and after = is how we want to give its value
new_col

new_col2<- panda_data %>%
	mutate(genetic_dif = genetic_value1 - genetic_value2, weight_g= weight_kg *1000) # you can create multiple columns at once 
new_col2
```
> Can you create a new column call zero and give it a value of 0 ?


###  `summarise()`   
Calculate summary statistics among all rows or rows within certain grouping, often used in combination with `group_by()` 
```{r}
sum_table <- panda_data%>% 
summarise (mean(weight_kg))
sum_table

sum_table2 <- panda_data%>% 
summarise (avg_wt= mean(weight_kg), min_wt= min(weight_kg))
sum_table2
```


### `group_by()`   
Divide data rows into groups based on grouping column(s) provided, often used in combination with other functions which define what you do with them after placing them in groups. When `group_by()` and `summarise()` are used together, you are essentially telling R to separate rows into different groups, and for each groups you use `summarise()` to generate a series of summary statistics that characterize the column values.    
```{r}
group_summary<- panda_data %>%
  group_by(base) %>%
  summarise(avg_wt= mean(weight_kg), 		min_wt= min(weight_kg))
group_summary
```

You can also create groups by the combination of two or multiple columns
```{r}
group_summary2<- panda_data %>%
  group_by(base, sex) %>%
  summarise(avg_wt= mean(weight_kg), 		min_wt= min(weight_kg))
group_summary2
```


###  Join table  
read in another table
```{r}
panda_data_med<-read.csv(file="Data/panda_data_med.csv")
```
                          
*  `left_join()`   
Returns all records from the left table, and the matched (matched by shared ID columns) records from the right table. The result is NULL from the right side, if there is no match.
```{r}
left_join(panda_data, panda_data_med, by = c("year"= "year_vaccination"))

```

left join by multiple ID columns
```{r}
left_join(panda_data, panda_data_med, by = c("year" = "year_vaccination", "ID" = "ID"))
```

Other than `left_join()` there are a few other join functions that would join table differently. Sometimes you will find them useful for a specific table you want to make, but in general, you can reply on `left_join()` for most of the job.   
* `right_join()`: similar to left join, it keeps all records from the right table instead.  
* `inner_join()`: return only the matched records from both tables.  
* `full_join()`: return all records in both tables.  


### Optional: Convert between wide and long table

*  `gather()`  
Convert wide table to long table
```{r}
library(tidyr)
```

```{r}
to_longtable<- select(panda_data, panda_name, ID, contains("genetic")) %>%
  gather( key=genetic_number, value=genetic_value,  genetic_value1:genetic_value3)
head(to_longtable)
```

*  `spread()`   
Does the opposite, convert long table to wide table
```{r}
to_widetable<- spread(panda_data_med, vaccine_type, year_vaccination)
head(to_widetable)
```